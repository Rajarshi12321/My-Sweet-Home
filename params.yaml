MLFLOW_EXPERIMENT_NAME: "Model Tuning Experiment"

MODELS:
  DecisionTree:
    criterion:
      - squared_error
      - friedman_mse
      # - absolute_error
      # - poisson
    splitter:
      - best
      - random
  #   max_features:
  #     - sqrt
  #     - log2
  # RandomForest:
  #   criterion:
  #     - squared_error
  #     - friedman_mse
  #     - absolute_error
  #     - poisson
  #   max_features:
  #     - sqrt
  #     - log2
  #     - null  # Assuming 'None' means null or no specified value
  #   n_estimators:
  #     - 8
  #     - 16
  #     - 32
  #     - 64
  #     - 128
  #     - 256
  # GradientBoosting:
  #   loss:
  #     - squared_error
  #     - huber
  #     - absolute_error
  #     - quantile
  #   learning_rate:
  #     - 0.1
  #     - 0.01
  #     - 0.05
  #     - 0.001
  #   subsample:
  #     - 0.6
  #     - 0.7
  #     - 0.75
  #     - 0.8
  #     - 0.85
  #     - 0.9
  #   criterion:
  #     - squared_error
  #     - friedman_mse
  #   max_features:
  #     - auto
  #     - sqrt
  #     - log2
  #   n_estimators:
  #     - 8
  #     - 16
  #     - 32
  #     - 64
  #     - 128
  #     - 256
  # LinearRegression: {}
  # XGBRegressor:
  #   learning_rate:
  #     - 0.1
  #     - 0.01
  #     - 0.05
  #     - 0.001
  #   n_estimators:
  #     - 8
  #     - 16
  #     - 32
  #     - 64
  #     - 128
  #     - 256
  # AdaBoostRegressor:
  #   learning_rate:
  #     - 0.1
  #     - 0.01
  #     - 0.5
  #     - 0.001
  #   loss:
  #     - linear
  #     - square
  #     - exponential
  #   n_estimators:
  #     - 8
  #     - 16
  #     - 32
  #     - 64
  #     - 128
  #     - 256
